{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from scipy.spatial import ConvexHull\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightglue\n",
    "from lightglue import LightGlue, SuperPoint, DISK, viz2d\n",
    "from lightglue.utils import rbd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 849/849 [00:06<00:00, 130.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images: torch.Size([849, 3, 440, 440])\n"
     ]
    }
   ],
   "source": [
    "df_test, test_dataset, match_results, q_pids, topk_idx, topk_names, match_mat, distmat, images = load_miewid_data('/home/cabidi/XAI/wbia-plugin-miew-id/wbia_miew_id/runs/miewid-training/beluga-example-exp-1/visualizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_convex_polygons(X: ..., dbscan_kwargs: dict = {\"eps\":0.3, \"min_samples\":3}) -> [ConvexHull]:\n",
    "    \"\"\"A polygon generator that uses the DBSCAN and ConvexHull algorithms from sklearn.\n",
    "\n",
    "    Args:\n",
    "        X (np.array, torch.Tensor): (num_samples,...)-shaped array of un-normalized data points\n",
    "        dbscan_kwargs (dict, optional): kwargs to provide to DBSCAN. Defaults to {\"eps\":0.5, \"min_samples\":3}.\n",
    "\n",
    "    Returns:\n",
    "        output: a set of k  drawn in the same (un-normalized) coordinate system as X\n",
    "    \"\"\"\n",
    "    if not isinstance(X, type(np.array)):\n",
    "        X = np.array(X)\n",
    "    \n",
    "    # Normalize input data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X_new = scaler.transform(X)\n",
    "    # print(f\"X mean: {scaler.mean_}\\nX variance: {scaler.var_}\")\n",
    "\n",
    "    # Run DBSCAN\n",
    "    # print(f\"Running DBSCAN with args {dbscan_kwargs}\")\n",
    "    db = DBSCAN(**dbscan_kwargs).fit(X_new)\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    # n_clusters_ = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "    # n_noise_ = list(db.labels_).count(-1)\n",
    "    # print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "    # print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "\n",
    "    # Extract the convex hull for each core sample set\n",
    "    hulls = []\n",
    "    for label in set(db.labels_):\n",
    "        # Condition on samples matching label\n",
    "        label_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        label_mask[db.labels_ == label] = True\n",
    "        \n",
    "        # Condition on samples in current core set\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        \n",
    "        # Extract core sample set\n",
    "        core_points = X[core_samples_mask & label_mask]\n",
    "\n",
    "        # Compute convex hull if there are more samples than lower bound\n",
    "        if len(core_points) > 3:\n",
    "            hull = ConvexHull(core_points)\n",
    "            hulls.append(hull)\n",
    "\n",
    "    return hulls\n",
    "    \n",
    "    # Un-normalize data\n",
    "    # hulls = np.array(hulls)\n",
    "    # if len(hulls) > 0:\n",
    "    #     hulls_denormalized = scaler.inverse_transform(hulls)\n",
    "    #     return hulls_denormalized\n",
    "    # return hulls\n",
    "\n",
    "def _lightglue(extractor, matcher, image0: torch.Tensor, image1: torch.Tensor) -> dict:\n",
    "    feats0 = extractor.extract(image0.to(device))\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    return feats0, feats1, matches01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 51/849 [00:59<15:28,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "### Boilerplate setup\n",
    "# Files\n",
    "saveroot = \"/srv/transparency/wildbook_prototype/data/matches/figures/lightglue/\"\n",
    "os.makedirs(saveroot, exist_ok=True)\n",
    "\n",
    "# Tabular data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
    "\n",
    "# LightGlue+SuperPoint\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)\n",
    "\n",
    "### Construct data for query-match pairs\n",
    "idx_to_match_idxs = {\n",
    "    idx:{\"topk_indices\":topk_idx[idx].tolist(), \"match_indicators\":match_mat[idx].tolist()}\n",
    "    for idx in range(len(images))\n",
    "}\n",
    "for i, (query_idx, vals) in enumerate(tqdm(idx_to_match_idxs.items())):\n",
    "    # Extract query image\n",
    "    image0 = images[query_idx]\n",
    "\n",
    "    # Extract top-k indices of matches and whether they were true matches or not\n",
    "    topk_indices = vals[\"topk_indices\"]\n",
    "    match_indicators = vals[\"match_indicators\"]\n",
    "\n",
    "    # Iterate through top-k matches\n",
    "    rendered_images = []\n",
    "    rendered_polygon_images = []\n",
    "    for rank, (match_idx, is_match) in enumerate(zip(topk_indices, match_indicators)):\n",
    "        # Extract match image\n",
    "        image1 = images[match_idx]\n",
    "\n",
    "        # Run LightGlue\n",
    "        feats0, feats1, matches01 = _lightglue(extractor, matcher, image0, image1)\n",
    "\n",
    "        # Visualize with lines and polygons\n",
    "        savepath = Path(saveroot, f\"lightglue_{query_idx}_{match_idx}.png\")\n",
    "        \n",
    "        # Pre-processing: remove batch dimension\n",
    "        feats0, feats1, matches01 = [\n",
    "            rbd(x) for x in [feats0, feats1, matches01]\n",
    "        ]\n",
    "        kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "        m_kpts0, m_kpts1 = kpts0[matches[..., 0]].cpu().numpy(), kpts1[matches[..., 1]].cpu().numpy()\n",
    "\n",
    "        # Generate hulls (requires >= match keypoints for convex polygon to be generated)\n",
    "        if len(m_kpts0) >= 3:\n",
    "            hulls_mkpts0 = compute_convex_polygons(m_kpts0, dbscan_kwargs={\"eps\":0.3, \"min_samples\":3})\n",
    "        else:\n",
    "            hulls_mkpts0 = []\n",
    "        if len(m_kpts1) >= 3:\n",
    "            hulls_mkpts1 = compute_convex_polygons(m_kpts1, dbscan_kwargs={\"eps\":0.3, \"min_samples\":3})\n",
    "        else:\n",
    "            hulls_mkpts0 = []\n",
    "\n",
    "        # Post-processing on hulls to get them to fit in pandas dataframe\n",
    "        # hulls_kpts0\n",
    "        # hulls_kpts1\n",
    "\n",
    "        # Extract score of query-match pair\n",
    "        score = distmat[query_idx, match_idx]\n",
    "\n",
    "        # Store computed results\n",
    "        data = {\n",
    "            \"query_idx\":    query_idx,\n",
    "            \"match_idx\":    match_idx,\n",
    "            \"score\":        score,\n",
    "            \"rank\":         rank,\n",
    "            \"is_match\":     is_match,\n",
    "            \"query_kpts\":   [m_kpts0],\n",
    "            \"match_kpts\":   [m_kpts1],\n",
    "            \"query_polygons\":   [hulls_mkpts0], \n",
    "            \"match_polygons\":   [hulls_mkpts1],\n",
    "            \"query_num_polygons\":   len(hulls_mkpts0),\n",
    "            \"match_num_polygons\":   len(hulls_mkpts1),\n",
    "            #\"polygons_iou\":\n",
    "        }\n",
    "        df = pd.concat((df, pd.DataFrame(data)), axis=0)\n",
    "    \n",
    "    if i > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      2\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m ranks, query_num_polygons, match_num_polygons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mlist\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_num_polygons\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mlist\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_num_polygons\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ranks, query_num_polygons, match_num_polygons = list(df['rank']), list(df['query_num_polygons']), list(df['match_num_polygons'])\n",
    "plt.scatter(ranks + np.random.normal(0.0, 0.1, size=len(ranks)), query_num_polygons + np.random.normal(0.0, 0.1, size=len(query_num_polygons)), c='red', marker='.')\n",
    "plt.scatter(ranks + np.random.normal(0.0, 0.1, size=len(ranks)), match_num_polygons + np.random.normal(0.0, 0.1, size=len(match_num_polygons)), c='green', marker='.')\n",
    "#plt.scatter(ranks, query_num_polygons, c='red', marker='.')\n",
    "#plt.scatter(ranks, match_num_polygons, c='green', marker='.')\n",
    "#\n",
    "# ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "# Get keypoints\n",
    "f0, f1, m01 = [\n",
    "        rbd(x) for x in [feats0, feats1, matches01]\n",
    "    ]  # remove batch dimension\n",
    "\n",
    "kpts0, kpts1, matches = f0[\"keypoints\"].cpu(), f1[\"keypoints\"].cpu(), m01[\"matches\"].cpu()\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "\n",
    "# Normal scaling\n",
    "X = StandardScaler().fit_transform(m_kpts0)\n",
    "\n",
    "# Run DBSCAN\n",
    "db = DBSCAN(eps=0.5, min_samples=3).fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "\n",
    "# Extract core set\n",
    "unique_labels = set(labels)\n",
    "core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "# Plot core vs non-core samples\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = labels == k\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(\n",
    "        xy[:, 0],\n",
    "        xy[:, 1],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=5,\n",
    "    )\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(\n",
    "        xy[:, 0],\n",
    "        xy[:, 1],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=3,\n",
    "    )\n",
    "\n",
    "plt.title(f\"Estimated number of clusters: {n_clusters_}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT GRADCAM INSTALLATION HERE #\n",
    "#pip install ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT GRADCAM BOILERPLATE CODE HERE #\n",
    "# imports\n",
    "\n",
    "# helpers\n",
    "\n",
    "# main functions\n",
    "def _gradcam(*args):\n",
    "    pass\n",
    "\n",
    "def _vis_gradcam(*args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BENCHMARK GRADCAM HERE #\n",
    "#%timeit -n 100 _gradcam(random.choice(images), random.choice(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through instance-match pairs\n",
    "idx_to_match_idxs = {idx:topk_idx[idx].tolist() for idx in range(len(images))}\n",
    "for idx, match_idxs in tqdm(idx_to_match_idxs.items()):\n",
    "    image0 = images[idx]\n",
    "    for match in match_idxs:\n",
    "        image1 = images[match]\n",
    "        # INSERT GRADCAM VISUALIZATION CODE HERE #\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightglue-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
